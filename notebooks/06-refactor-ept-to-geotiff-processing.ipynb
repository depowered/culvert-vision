{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Parameters\n",
    "First we need to gather all of the configuration parameters that went into the initial processing so that we can begin to organize them into usable objects and define reasonable defaults. The following cells summarize the parameters used in each step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create an AOI geometry\n",
    "from shapely import Point\n",
    "import geopandas\n",
    "\n",
    "point_of_interest = Point(-90.47416614755436, 47.738145812431185)  # EPSG:4326\n",
    "input_gdf: geopandas.GeoDataFrame = geopandas.GeoDataFrame(\n",
    "    geometry=[point_of_interest], crs=\"EPSG:4326\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "\n",
    "input_geometry: GeoDataFrame | GeoSeries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Select intersecting tile(s)\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "tiles_kwargs = {\n",
    "    \"filename\": Path(\"../data/interim/tile_index.gpkg\").resolve(),\n",
    "    \"layer\": \"tile_index\",\n",
    "    \"mask\": input_gdf.to_crs(\"EPSG:6344\"),\n",
    "    \"where\": \"workunit='MN_RainyLake_1_2020'\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "tile_index_source: Path  # .gpkg or .parquet created from build_tile_index.py\n",
    "tile_index_read_kwargs: dict[str, Any]  # Might not be necessary; just use an intersect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Copied from ../config/mn_rainylake_1_2020.json\n",
    "ept_json_href = (\n",
    "    \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/MN_RainyLake_1_2020/ept.json\"\n",
    ")\n",
    "enriched_tiles = tiles.assign(ept_json_href=ept_json_href)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import HttpUrl\n",
    "\n",
    "\n",
    "# Either add this field to the tile layer or create a separate file/layer to read this from\n",
    "ept_json_href: HttpUrl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create buffered tile WKT\n",
    "buffer_dist = 5  # meters\n",
    "pipeline_params[\"buffered_wkt\"] = (\n",
    "    pipeline_params.buffer(distance=buffer_dist).to_crs(\"EPSG:3857\").to_wkt()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_n_cells: int = 3  # Multiply by the resolution to get the buffer distance\n",
    "ept_crs: str  # Read from ept.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Assign the EPSG string of the tiles to a field\n",
    "pipeline_params[\"out_srs\"] = pipeline_params.crs.srs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tile bounds are used later in the pipeline to define the raster extents,\n",
    "# so the reprojection crs should always be the same as the tiles.\n",
    "\n",
    "out_srs: str  # Calculate from tiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Assign fields for the filters.faceraster parameters\n",
    "resolution = 0.30  # meters\n",
    "\n",
    "pipeline_params[\"resolution\"] = resolution\n",
    "pipeline_params[\"width\"] = (\n",
    "    (\n",
    "        pipeline_params.geometry.bounds[\"maxx\"]\n",
    "        - pipeline_params.geometry.bounds[\"minx\"]\n",
    "        + resolution\n",
    "    )\n",
    "    / resolution\n",
    ").astype(int)\n",
    "pipeline_params[\"height\"] = (\n",
    "    (\n",
    "        pipeline_params.geometry.bounds[\"maxy\"]\n",
    "        - pipeline_params.geometry.bounds[\"miny\"]\n",
    "        + resolution\n",
    "    )\n",
    "    / resolution\n",
    ").astype(int)\n",
    "pipeline_params[\"origin_x\"] = pipeline_params.geometry.bounds[\"minx\"]\n",
    "pipeline_params[\"origin_y\"] = pipeline_params.geometry.bounds[\"miny\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution: float\n",
    "width: int  # Calculate from tile and resolution\n",
    "height: int  # Calculate from tile and resolution\n",
    "origin_x: float  # Calculate from tile\n",
    "origin_y: float  # Calculate from tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Assign the output_file field\n",
    "output_dir = Path(\"../data/processed\").resolve()\n",
    "pipeline_params[\"output_file\"] = \"../data/processed/\" + pipeline_params[\"name\"] + \"_1ft.tif\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir: Path\n",
    "output_prefix: str | None\n",
    "output_postfix: str | None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined parameters\n",
    "The following cell restates the variables above that need to be set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined parameters\n",
    "input_geometry: GeoDataFrame | GeoSeries\n",
    "tile_index_source: Path  # .gpkg or .parquet created from build_tile_index.py\n",
    "buffer_n_cells: int = 3  # Multiply by the resolution to get the buffer distance\n",
    "resolution: float\n",
    "output_dir: Path\n",
    "output_prefix: str | None\n",
    "output_postfix: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class PDALReader(BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "class PDALFilter(BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "class PDALWriter(BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "class FaceRasterWriter(PDALWriter):\n",
    "    tag: str = \"face_raster_writer\"\n",
    "    type: str = \"writers.raster\"\n",
    "    gdaldriver: str = \"GTiff\"\n",
    "    gdalopts: str = \"COMPRESS=DEFLATE\"\n",
    "    data_type: str = \"float32\"\n",
    "    nodata: int | float = -999999\n",
    "\n",
    "    def stage_dict(self, filename: str):\n",
    "        d = self.dict(exclude_none=True)\n",
    "        d.update(filename=filename)\n",
    "        return d\n",
    "\n",
    "\n",
    "class EptPipeline(BaseModel):\n",
    "    tile_index_source: Path\n",
    "    resolution: float\n",
    "    buffer_n_cells: int = 3\n",
    "    pdal_writers: list[PDALWriter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'face_raster_writer',\n",
       " 'type': 'writers.raster',\n",
       " 'gdaldriver': 'GTiff',\n",
       " 'gdalopts': 'COMPRESS=DEFLATE',\n",
       " 'data_type': 'float32',\n",
       " 'nodata': -999999,\n",
       " 'filename': '123.tif'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceraster = FaceRasterWriter()\n",
    "# faceraster.dict(exclude_none=True)\n",
    "faceraster.stage_dict(\"123.tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline construction classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Protocol\n",
    "from shapely import Polygon\n",
    "import pdal\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "StageDict = dict[str, str | int | float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PDALPipelineFactory:\n",
    "    point_source: PDALPointSource\n",
    "    products: list[PDALProduct]\n",
    "\n",
    "    def __call__(self, tile: Tile) -> pdal.Pipeline:\n",
    "        ...\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tile:\n",
    "    name: str\n",
    "    epsg_code: int\n",
    "    ept_json_url: str\n",
    "    geom: Polygon\n",
    "\n",
    "    @staticmethod\n",
    "    def from_gdf(tiles_gdf: GeoDataFrame) -> list[Tile]:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def origin_x(self) -> float:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def origin_y(self) -> float:\n",
    "        ...\n",
    "\n",
    "    def width(self, resolution: float) -> int:\n",
    "        ...\n",
    "\n",
    "    def height(self, resolution: float) -> int:\n",
    "        ...\n",
    "\n",
    "    def to_wkt(self) -> str:\n",
    "        ...\n",
    "\n",
    "    def buffer(self, dist: float) -> Tile:\n",
    "        ...\n",
    "\n",
    "    def buffered_ept_filter_as_wkt(self, dist: float) -> str:\n",
    "        ...\n",
    "\n",
    "\n",
    "class PDALPointSource(Protocol):\n",
    "\n",
    "    def get_point_source_stages(self, tile: Tile, buffer_dist: float) -> list[StageDict]:\n",
    "        ...\n",
    "\n",
    "\n",
    "class PDALProduct(Protocol):\n",
    "\n",
    "    def get_product_stages(self, tile: Tile) -> list[StageDict]:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VendorClassifiedGroundPoints:\n",
    "    buffer_ept_filter_dist: float\n",
    "    tag: str = \"vendor_classified_ground_points\"\n",
    "\n",
    "    def get_point_source_stages(self, tile: Tile) -> list[StageDict]:\n",
    "        return [\n",
    "            {\n",
    "                \"tag\": \"read_data\",\n",
    "                \"type\": \"readers.ept\",\n",
    "                \"filename\": tile.ept_json_url,\n",
    "                \"polygon\": tile.buffered_ept_filter_as_wkt(self.buffer_ept_filter_dist),\n",
    "            },\n",
    "            {\n",
    "                \"tag\": \"ground_only\",\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"Classification[2:2]\",\n",
    "            },\n",
    "            {\n",
    "                \"tag\": self.tag,\n",
    "                \"type\": \"filters.reprojection\",\n",
    "                \"out_srs\": f\"EPSG:{tile.epsg_code}\",\n",
    "            },\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DEMFromDelauneyMesh:\n",
    "    input_tag: str\n",
    "    resolution: float\n",
    "    output_dir: Path\n",
    "    output_prefix: Optional[str]\n",
    "    output_postfix: Optional[str]\n",
    "    output_ext: str = \".tif\"\n",
    "    gdaldriver: str = \"GTiff\"\n",
    "    gdalopts: str = \"COMPRESS=DEFLATE\"\n",
    "    data_type: str = \"float32\"\n",
    "    nodata: int | float = -999999\n",
    "\n",
    "    def get_pipeline_stages(self, tile: Tile):\n",
    "        return [\n",
    "            {\n",
    "                \"tag\": \"faceraster\",\n",
    "                \"type\": \"filters.faceraster\",\n",
    "                \"inputs\": [self.input_tag],\n",
    "                \"resolution\": self.resolution,\n",
    "                \"width\": tile.width(self.resolution),\n",
    "                \"height\": tile.height(self.resolution),\n",
    "                \"origin_x\": tile.origin_x,\n",
    "                \"origin_y\": tile.origin_y,\n",
    "            },\n",
    "            {\n",
    "                \"tag\": \"write_raster\",\n",
    "                \"type\": \"writers.raster\",\n",
    "                \"filename\": str(self.output_dir),\n",
    "                \"gdaldriver\": self.gdaldriver,\n",
    "                \"gdalopts\": self.gdalopts,\n",
    "                \"data_type\": self.data_type,\n",
    "                \"nodata\": self.nodata,\n",
    "            },\n",
    "        ]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Generate pipelines\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pipeline_factory \u001b[39m=\u001b[39m PDALPipelineFactory(\n\u001b[1;32m     26\u001b[0m     point_source\u001b[39m=\u001b[39mpoint_source,\n\u001b[1;32m     27\u001b[0m     products\u001b[39m=\u001b[39m[dem]\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m pipelines \u001b[39m=\u001b[39m [pipeline_factory(tile) \u001b[39mfor\u001b[39;00m tile \u001b[39min\u001b[39;00m tiles]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Define point source\n",
    "point_source = VendorClassifiedGroundPoints(\n",
    "    buffer_ept_filter_dist=10  # meters\n",
    ")\n",
    "\n",
    "# Define pipeline product\n",
    "dem = DEMFromDelauneyMesh(\n",
    "    input_tag=\"vendor_classified_ground_points\",\n",
    "    resolution=0.5,  # meters\n",
    "    output_dir=Path(\"../data/interim/\").resolve(),\n",
    "    output_prefix=\"experiment01_\",\n",
    "    output_postfix=\"_half_meter_dem\",\n",
    ")\n",
    "\n",
    "# Select tiles\n",
    "tiles_gdf = GeoDataFrame({\n",
    "    \"name\": [\"dummy_tile\"],\n",
    "    \"epsg_code\": [1234],\n",
    "    \"ept_json_url\": [\"http://example.com\"],\n",
    "    \"geometry\": [Polygon(((0., 0.), (0., 1.), (1., 1.), (1., 0.), (0., 0.)))]\n",
    "})\n",
    "tiles = Tile.from_gdf(tiles_gdf)\n",
    "\n",
    "# Generate pipelines\n",
    "pipeline_factory = PDALPipelineFactory(\n",
    "    point_source=point_source,\n",
    "    products=[dem]\n",
    ")\n",
    "pipelines = [pipeline_factory(tile) for tile in tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "culvert-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
